# **WEEK 10**

## **Gradient Descent With Large Datasets**  

*Learning with large datasets:*  
When using very large datasets, computation can be very expensive.  
Before looking at how to deal with a million examples, let's first see why not use only a 1000 examples.  
Before investing a lot of effort on developing a software, a good sanity check is to first train on a small set and plot the learning curve.  
If we find a hihg-variance algo, it is safe to assume that more data will indeed be useful.  

*Stochastic Gradient Descent:*  
